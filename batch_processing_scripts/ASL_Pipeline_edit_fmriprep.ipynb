{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d741682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary python packages for analysis\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import nilearn\n",
    "import string\n",
    "import glob\n",
    "import pathlib\n",
    "import json\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import chain\n",
    "import ipywidgets\n",
    "import multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7454cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file paths to access the necessary data\n",
    "\n",
    "project_folder = '/work/qlab_nu/NAS_Data/projects/blast/data/derivatives_new/' #Set the project folder path \n",
    "fmriprep_folder= os.path.join(project_folder,'fs_edited/fmriprep') # Make sure this folder points to the fMRI prep folder\n",
    "bids_folder= os.path.join(project_folder,'bids') # Make sure this folder points to BIDS directory\n",
    "output_folder = os.path.join(project_folder, 'first_level_output/edit_fmriprep') # This is the folder that saves the first level models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6ffe1f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality bad subject removal list:        part_id  run\n",
      "168  blastc072    4\n",
      "219  blastc230    4\n",
      "245  blastc513    1\n",
      "246  blastc513    2\n",
      "262  blastc549    1\n",
      "263  blastc549    2\n",
      "265  blastc549    4\n"
     ]
    }
   ],
   "source": [
    "# Extract the subject IDs of all the subjects available for  analysis\n",
    "\n",
    "task = \"asl\" #Set the task. Should match the BIDS file name\n",
    "output_folder = os.path.join(output_folder, task)\n",
    "os.makedirs(output_folder,exist_ok= True)\n",
    "no_runs =4 # Max number of runs for each subject\n",
    "restcond = 'rest'\n",
    "# Search the potential subject names in fMRIprep folder\n",
    "potential_sub_list = [pathlib.PurePath(file).name for file in glob.iglob(os.path.join(fmriprep_folder , \"sub-*/\"))]\n",
    "runs_avail= {}\n",
    "scans_avail={}\n",
    "for sub in potential_sub_list:\n",
    "    sub_strng = \"{}_task-{}_run-0[1-{}]_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\".format(sub,task, no_runs)\n",
    "    scans_avail[sub]= [pathlib.PurePath(file).name for file in glob.iglob(os.path.join(fmriprep_folder, sub,'func', sub_strng))]\n",
    "    runs_avail[sub] = [int(f.split('_')[2][-1]) for f in scans_avail[sub]]\n",
    "\n",
    "# Lets remove the subjects by removing subjects with no scans\n",
    "scans_avail  = {sub:val for sub, val in scans_avail.items() if val} \n",
    "runs_avail  = {sub:val for sub, val in runs_avail.items() if val} \n",
    "\n",
    "# Lets also remove the subjects by removing subjects with more than 30% of bad data (Framewise Displacement > 2mm)\n",
    "sub_removal_list = pd.read_csv(\"/work/qlab_nu/NAS_Data/projects/blast/data/derivatives_new/subject_list/aslTP_outlier.csv\")\n",
    "sub_removal = sub_removal_list.loc[sub_removal_list['remove'].astype(bool), ['part_id', 'run']]\n",
    "print(\"Data quality bad subject removal list:\", sub_removal)\n",
    "\n",
    "for i,row in sub_removal.iterrows():\n",
    "    temp_subject = 'sub-'+row['part_id']\n",
    "    if temp_subject in runs_avail.keys():\n",
    "        runs_avail['sub-'+row['part_id']].remove(row['run'])\n",
    "\n",
    "#Further lets remove the scans with empty event files\n",
    "\n",
    "stimcond= \"stimcond\"  # THe column in the event file which is used for the modeling the stimuli in the GLM\n",
    "conditions= set()\n",
    "subject_cond = {}# This will have information about conidtions avaialable for each subject across all available runs.\n",
    "everuns_avail={}\n",
    "subject_run_conds = {} # This will save  informatin about conditions in wach run\n",
    "\n",
    "for sub, runs in runs_avail.items():\n",
    "    conds =set()\n",
    "    everuns=[]\n",
    "    conds_run =[]\n",
    "    for run in runs:\n",
    "        eve_filename= \"{}_task-{}_run-0{}_events.tsv\".format(sub, task, run)\n",
    "        # Check that the event file exists for a bids run first\n",
    "        if os.path.isfile(os.path.join(bids_folder, sub, 'func', eve_filename)):\n",
    "            events = pd.read_csv(os.path.join(bids_folder, sub, 'func', eve_filename), sep='\\t')\n",
    "            # Then check if the event file is not empty\n",
    "            if len(events.index) >0:\n",
    "                everuns.append(run)\n",
    "                conds = conds.union(set(events[stimcond]))\n",
    "                conds_run.append(list(np.unique(events[stimcond])))\n",
    "    # Gather the runs that have BOTH scans and event files for each subject\n",
    "    everuns_avail[sub]=everuns\n",
    "    subject_cond[sub] = list(conds)\n",
    "    conditions = conditions.union(conds)\n",
    "    subject_run_conds[sub] = conds_run \n",
    "    \n",
    "# Now lets remove the subjects who do not have all the needed conditions in their runs   \n",
    "subject_cond = {subs:conds  for subs, conds in subject_cond.items() if set(conds)==set(conditions)}\n",
    "# Only include scans with corresponding event files for each subject\n",
    "runs_avail  = {sub:run for sub, run in everuns_avail.items() if run and sub in subject_cond.keys()}\n",
    "# print(runs_avail)\n",
    "subject_run_conds  = {sub:cond for sub, cond in subject_run_conds.items() if sub in subject_cond.keys()}\n",
    "# print(subject_run_conds)\n",
    "conditions =list(conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c1cdab49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the task asl the following subjects and runs are available for analyses:\n",
      "sub-blasta001 1 3 4\n",
      "sub-blasta012 1 2 3 4\n",
      "sub-blasta038 1 2 3 4\n",
      "sub-blasta044 1 2 3 4\n",
      "sub-blasta055 1 2 3 4\n",
      "sub-blasta056 1 2 3 4\n",
      "sub-blasta057 2 3 4\n",
      "sub-blasta058 1 2 3 4\n",
      "sub-blasta060 1 2 3 4\n",
      "sub-blasta069 1 2 3 4\n",
      "sub-blasta075 1 2 3 4\n",
      "sub-blastc019 1 2 4\n",
      "sub-blastc059 1 2 3 4\n",
      "sub-blastc061 1 2 3 4\n",
      "sub-blastc071 1 2 3 4\n",
      "sub-blastc147 1 2 3 4\n",
      "sub-blastc149 1 2 3 4\n",
      "sub-blastc170 1 2 3 4\n",
      "sub-blastc206 1 2 3 4\n",
      "sub-blastc213 2 3 4\n",
      "sub-blastc224 2 3 4\n",
      "sub-blastc228 1 2 3 4\n",
      "sub-blastc229 1 2 3 4\n",
      "sub-blastc232 1 2 3 4\n",
      "sub-blastc233 1 2 3 4\n",
      "sub-blastc267 1 2 3 4\n",
      "sub-blastc475 1 2 3 4\n",
      "sub-blastc480 1 2 3\n",
      "sub-blastc481 1 2 3 4\n",
      "sub-blastc516 1 2 3 4\n",
      "sub-blastc522 1 2 3 4\n",
      "sub-blastc540 1 2 3 4\n",
      "sub-blastc553 1 2 3 4\n",
      "sub-blastc558 1 2 3 4\n"
     ]
    }
   ],
   "source": [
    "# Now lets print the subject list and runs avaiable forthe task analysis\n",
    "\n",
    "import copy\n",
    "print(\"For the task\",task, \"the following subjects and runs are available for analyses:\")\n",
    "for sub, runs in runs_avail.items():\n",
    "    print(sub, ' '.join(map(str ,runs)))\n",
    "    \n",
    "# final_subject_list = copy.deepcopy(runs_avail)\n",
    "# R1 = 'Y'\n",
    "# while R1=='Y':\n",
    "#     R1 = input(\"Do you want to remove any subjects? Y or N\")\n",
    "#     if R1=='Y':\n",
    "#         R2 = input(\"Do you have a file that removes that list subjects that you want to use? Y or N\")\n",
    "#         if R2 =='Y':\n",
    "#             R3= input(\"Input the path of the file\")\n",
    "#             # Path of file: /work/qlab_nu/NAS_Data/projects/blast/data/derivatives_new/subject_list/aslTP_outlier.csv\n",
    "#             sub_removal_list = pd.read_csv(R3)\n",
    "#             sub_removal =sub_removal_list.loc[sub_removal_list['remove'].astype(bool), ['part_id', 'run']]\n",
    "#             print(sub_removal)\n",
    "            \n",
    "#             for i,row in sub_removal.iterrows():\n",
    "#                 temp_subject = 'sub-'+row['part_id']\n",
    "                \n",
    "#                 if temp_subject in final_subject_list.keys():\n",
    "#                     final_subject_list['sub-'+row['part_id']].remove(row['run'])\n",
    "#                     R1 = 'N'\n",
    "            \n",
    "#         else:\n",
    "#             subs= input(\"Input a list of subjects you want removed and seperate each subject seperated by commas\")\n",
    "#             subs = subs.split(\", \")\n",
    "#             for s in subs:\n",
    "#                 if s in final_subject_list.keys():\n",
    "#                     del final_subject_list[s]\n",
    "#     elif R1 =='N':\n",
    "#         break;\n",
    "#     else:\n",
    "#         print(\"Please enter either Y or N as valid output\")\n",
    "        \n",
    "        \n",
    "# print(\"For the task\",task, \"the final list of subjects and runs will be used for analyses:\")\n",
    "# for sub, runs in final_subject_list.items():\n",
    "#     print(sub, ' '.join(map(str ,runs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "184de349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a list of contasts to be calculated. Contrasts should be in the format of cond1minuscond2. If  all entered press Enter toneSminusrest\n",
      "Enter a list of contasts to be calculated. Contrasts should be in the format of cond1minuscond2. If  all entered press Enter toneRminusrest\n",
      "Enter a list of contasts to be calculated. Contrasts should be in the format of cond1minuscond2. If  all entered press Enter syllableSminusrest\n",
      "Enter a list of contasts to be calculated. Contrasts should be in the format of cond1minuscond2. If  all entered press Enter syllableRminusrest\n",
      "Enter a list of contasts to be calculated. Contrasts should be in the format of cond1minuscond2. If  all entered press Enter \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For run-level analysis, these contrasts will be calculated:  ['syllableRminusrest', 'toneSminusrest', 'syllableSminusrest', 'toneRminusrest']\n"
     ]
    }
   ],
   "source": [
    "# Estimate run level contrasts\n",
    "from itertools import chain\n",
    "def check_contrast_run(cont):\n",
    "    unq_cond_runs = [list(x) for x in set(tuple(x) for x in list(chain.from_iterable(subject_run_conds.values())))]\n",
    "    return (any([set(cont.split(\"minus\")).issubset(set(cond)) for cond in unq_cond_runs]))\n",
    "\n",
    "contrasts_list = list()\n",
    "while True:\n",
    "    # e.g., Enter these one by one and press enter: toneSminusrest,toneRminusrest,syllableSminusrest,syllableRminusrest\n",
    "    cont = input(\"Enter a list of contasts to be calculated. Contrasts should be in the format of cond1minuscond2. If  all entered press Enter\")\n",
    "    if cont:\n",
    "        if (check_contrast_run(cont) and len(cont.split(\"minus\"))==2):\n",
    "            contrasts_list.append(cont)\n",
    "        else:\n",
    "            print(\"Contrast not valid. Enter a valid string.\")\n",
    "    else:\n",
    "        break\n",
    "\n",
    "contrasts_list = list(set(contrasts_list))\n",
    "print(\"For run-level analysis, these contrasts will be calculated: \", contrasts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "71d9fc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrasts that will be calculated at subject level:\n",
      "syllableRminusrest\n",
      "toneSminusrest\n",
      "syllableSminusrest\n",
      "toneRminusrest\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a list of additional contrasts to be calculated at subject level. Contrasts should be in the format of cond1minuscond2. If  all entered press Enter syllableSminussyllableR\n",
      "Enter a list of additional contrasts to be calculated at subject level. Contrasts should be in the format of cond1minuscond2. If  all entered press Enter toneSminustoneR\n",
      "Enter a list of additional contrasts to be calculated at subject level. Contrasts should be in the format of cond1minuscond2. If  all entered press Enter toneSminusrest\n",
      "Enter a list of additional contrasts to be calculated at subject level. Contrasts should be in the format of cond1minuscond2. If  all entered press Enter toneRminusrest\n",
      "Enter a list of additional contrasts to be calculated at subject level. Contrasts should be in the format of cond1minuscond2. If  all entered press Enter syllableSminusrest\n",
      "Enter a list of additional contrasts to be calculated at subject level. Contrasts should be in the format of cond1minuscond2. If  all entered press Enter syllableRminusrest\n",
      "Enter a list of additional contrasts to be calculated at subject level. Contrasts should be in the format of cond1minuscond2. If  all entered press Enter \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For subject-level analysis, these contrasts will be calculated:  ['syllableSminussyllableR', 'toneSminustoneR', 'syllableSminusrest', 'toneSminusrest', 'syllableRminusrest', 'toneRminusrest']\n"
     ]
    }
   ],
   "source": [
    "#Estimate subject level contrasts\n",
    "import copy\n",
    "contrasts_list_sub = copy.deepcopy(contrasts_list)\n",
    "print(\"Contrasts that will be calculated at subject level:\")\n",
    "for c in contrasts_list_sub:\n",
    "    print(c)\n",
    "while True:\n",
    "    # e.g., Enter these one by one and press enter: syllableSminussyllableR,toneSminustoneR,toneSminusrest,toneRminusrest,syllableSminusrest,syllableRminusrest\n",
    "    cont = input(\"Enter a list of additional contrasts to be calculated at subject level. Contrasts should be in the format of cond1minuscond2. If  all entered press Enter\")\n",
    "    if cont:\n",
    "        if (set(cont.split(\"minus\")).issubset(set(conditions)) and len(cont.split(\"minus\"))==2):\n",
    "            contrasts_list_sub.append(cont)\n",
    "        else:\n",
    "            print(\"Contrast not valid. Enter a valid string.\")\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "contrasts_list_sub = list(set(contrasts_list_sub))\n",
    "print(\"For subject-level analysis, these contrasts will be calculated: \", contrasts_list_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6875cd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define subject level contrasts. Here the contrasts are calculated across the multiple runs. So we calculate c\n",
    "import re\n",
    "from nilearn.glm.contrasts import compute_fixed_effects\n",
    "from nilearn.image import concat_imgs\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "import copy\n",
    "def estimate_subject_stats (subject, task, contrast, effect_files_list, var_files_list):\n",
    "    contrast_imgs = list(map(nib.load, effect_files_list))\n",
    "    variance_imgs = list(map(nib.load, var_files_list))   \n",
    "    \n",
    "    # Weighs the effect sizes by the inverse variance in fixed effects modeling\n",
    "    fixed_fx_contrast_img,fixed_fx_variance_img, fixed_fx_t_image = compute_fixed_effects(contrast_imgs, variance_imgs, mask= nilearn.datasets.fetch_icbm152_brain_gm_mask(), precision_weighted=True)\n",
    "    fixed_fx_contrast_img.to_filename(os.path.join(output_folder, 'subjectLevel', subject, \"{}_task-{}_contrast-{}_stat-effect_statmap.nii.gz\".format(subject, task, contrast)))\n",
    "    fixed_fx_variance_img.to_filename(os.path.join(output_folder, 'subjectLevel', subject, \"{}_task-{}_contrast-{}_stat-variance_statmap.nii.gz\".format(subject, task, contrast)))   \n",
    "    fixed_fx_t_image.to_filename(os.path.join(output_folder, 'subjectLevel', subject, \"{}_task-{}_contrast-{}_stat-t_statmap.nii.gz\".format(subject, task, contrast) )) \n",
    "    \n",
    "def create_sublevelContrasts(subject, runs, task, contrasts_list_sub):\n",
    "    design_matrices_list=  glob.glob(os.path.join(output_folder,'runLevel', subject, \"{}_task-{}_run-0{}_design-full.tsv\".format(subject, task, runs)))\n",
    "    # print(design_matrices_list)\n",
    "    design_matrices = [pd.read_csv(file, sep=\"\\t\" ) for file in design_matrices_list]\n",
    "    # print(design_matrices)\n",
    "    design_matrices = [ds.drop(columns= 'Unnamed: 0') for ds in design_matrices]                                        \n",
    "    for i, run in enumerate(runs):\n",
    "        design_matrices[i].columns =  [col+'_'+ str(run) for col in design_matrices[i].columns]\n",
    "        if i>0:\n",
    "            design_matrices[i].index += design_matrices[i-1].index[-1] + 1\n",
    "    design_matrices_combined = pd.concat(design_matrices)\n",
    "    design_matrices_combined.fillna(0, inplace=True)\n",
    "    for r in range(no_runs):\n",
    "        design_matrices_combined.rename(columns={'constant_{}'.format(r): 'run_{}'.format(r)}, inplace =True, errors = 'ignore')\n",
    "    design_matrices_combined['constant']=1\n",
    "    design_matrices_combined.to_csv(os.path.join(output_folder,'subjectLevel', subject, \"{}_task-{}_design.tsv\".format(subject, task)),sep='\\t')                                    \n",
    "    bold_files_list = glob.glob(os.path.join(fmriprep_folder, subject, 'func', \"{}_task-{}_run-0{}_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\".format(subject,task, runs)))\n",
    "    bold_files = list(map(nib.load, bold_files_list))\n",
    "    bold_data_combined = concat_imgs(bold_files)\n",
    "    samples_files_list= glob.glob(os.path.join(output_folder,'runLevel', subject, \"{}_task-{}_run-0{}_samples.txt\".format(subject, task, runs)))\n",
    "    sample_masks =[np.loadtxt(file, dtype='int') for file in samples_files_list]\n",
    "    sample_masks_combined = copy.deepcopy(sample_masks)\n",
    "    for i, run in enumerate(runs):\n",
    "        sample_masks_combined[i] += i*bold_files[i-1].shape[3] \n",
    "    sample_masks_combined = np.concatenate(sample_masks_combined).ravel()\n",
    "    np.savetxt(os.path.join(output_folder, 'subjectLevel', subject,\"{}_task-{}_samples.txt\".format(subject, task)),  sample_masks_combined , fmt='%d')                               \n",
    "    fmri_glm_sub = FirstLevelModel(subject_label='subject', minimize_memory=False);\n",
    "    fmri_glm_sub = fmri_glm_sub.fit(bold_data_combined , design_matrices=design_matrices_combined, sample_masks=sample_masks_combined);\n",
    "    contrasts_sub = dict()\n",
    "    contrasts_runs = dict()\n",
    "    for cname in contrasts_list_sub:\n",
    "            cond1, cond2 = tuple(cname.split('minus'))\n",
    "            if set(cname.split('minus')).issubset(subject_cond[subject]):\n",
    "                runs_cont = [runs_avail[subject][idx] for idx, conds in enumerate(subject_run_conds[subject]) if set(cname.split('minus')).issubset(set(conds))]\n",
    "                \n",
    "                if runs_cont:\n",
    "                    design_matrices_list_cont=  glob.glob(os.path.join(output_folder,'runLevel', subject, \"{}_task-{}_run-0{}_design-full.tsv\".format(subject, task, runs_cont)))\n",
    "                    design_matrices_cont = [pd.read_csv(file, sep=\"\\t\" ) for file in design_matrices_list_cont]\n",
    "                    design_matrices_cont = [ds.drop(columns= 'Unnamed: 0') for ds in design_matrices_cont] \n",
    "                    if (runs_cont== runs) and (all([len(ds.columns) for ds in design_matrices_cont])) and (all([set(design_matrices_cont[0].columns)==r for r in [set(ds.columns) for ds in design_matrices_cont[1:]]])):\n",
    "                        condition_matrix_cont = np.eye(design_matrices_cont[0].shape[1])\n",
    "                        condition_matrix_cont = {\n",
    "                        column: condition_matrix_cont[i]\n",
    "                        for i, column in enumerate(design_matrices_cont[0].columns) if column in conditions\n",
    "                        }\n",
    "                        contrasts_runs[cname] = condition_matrix_cont[cond1]- condition_matrix_cont[cond2]\n",
    "                    else:\n",
    "\n",
    "                        if (all([len(ds.columns) for ds in design_matrices_cont])) and (all([set(design_matrices_cont[0].columns)==r for r in [set(ds.columns) for ds in design_matrices_cont[1:]]])):\n",
    "                         # This part of the code is run if the columns of the design matrix are same across different runs \n",
    "                            bold_files_list_cont = glob.glob(os.path.join(fmriprep_folder, subject, 'func', \"{}_task-{}_run-0{}_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\".format(subject,task, runs_cont)))\n",
    "                            bold_files_cont = list(map(nib.load, bold_files_list_cont))\n",
    "\n",
    "                            samples_files_list_cont= glob.glob(os.path.join(output_folder,'runLevel', subject, \"{}_task-{}_run-0{}_samples.txt\".format(subject, task, runs_cont)))\n",
    "                            sample_masks_cont =[np.loadtxt(file, dtype='int') for file in samples_files_list_cont]\n",
    "                            fmri_glm_sub_cont = FirstLevelModel(subject_label='subject', minimize_memory=False) ;\n",
    "                            fmri_glm_sub_cont = fmri_glm_sub_cont.fit(bold_files_cont, design_matrices=design_matrices_cont, sample_masks=sample_masks_cont);\n",
    "                            condition_matrix_cont = np.eye(design_matrices_cont[0].shape[1])\n",
    "                            condition_matrix_cont = {\n",
    "                            column: condition_matrix_cont[i]\n",
    "                            for i, column in enumerate(design_matrices_cont[0].columns) if column in conditions\n",
    "                            }\n",
    "                            contrasts=dict()\n",
    "                            contrasts[cname] = condition_matrix_cont[cond1]- condition_matrix_cont[cond2]\n",
    "                            save_glm_to_bids(fmri_glm_sub_cont, contrasts, out_dir=os.path.join(output_folder, 'subjectLevel', subject), prefix= \"{}_task-{}\".format(subject, task))\n",
    "                            report_sub_cont = make_glm_report(fmri_glm_sub_cont, contrasts, title= 'Statistical report for subject: {} and task: {}'.format(subject, task), alpha =0.001,  bg_img='MNI152TEMPLATE',cluster_threshold=0, height_control='fpr',min_distance=8.0, plot_type='slice', two_sided=True);\n",
    "                            report_sub_cont.save_as_html(os.path.join(output_folder, 'subjectLevel', subject, '{}_task-{}_contrast-{}_contrasts-report.html'.format(subject, task, cname)));\n",
    "\n",
    "                        else:\n",
    "                             # This part of the code is run if the columns of the design matrix are not same across runs, either due to different nuissance regressors.\n",
    "                            effect_files_list = glob.glob(os.path.join(output_folder, 'runLevel', subject, \"{}_task-{}_run-0[0-9]_contrast-{}_stat-effect_statmap.nii.gz\".format(subject, task, cname.lower())))\n",
    "                            var_files_list = glob.glob(os.path.join(output_folder, 'runLevel', subject, \"{}_task-{}_run-0[0-9]_contrast-{}_stat-variance_statmap.nii.gz\".format(subject, task, cname.lower())))\n",
    "                            cstring = os.path.basename(effect_files_list[0])\n",
    "                            contrast = re.search(r\"contrast-[a-z]+\", cstring).group().split('-')[1]                            \n",
    "                            estimate_subject_stats (subject, task, contrast, effect_files_list, var_files_list)\n",
    "                            \n",
    "                elif (set(cname.split('minus')+[restcond]).issubset(subject_cond[subject])):          \n",
    "                    contrast_vals_img = np.zeros(design_matrices_combined.shape[1])\n",
    "                    cond1_runs = [runs_avail[subject][idx] for idx, conds in enumerate(subject_run_conds[subject]) if set([cond1,restcond]).issubset(set(conds))]\n",
    "                    cond2_runs = [runs_avail[subject][idx] for idx, conds in enumerate(subject_run_conds[subject]) if set([cond2,restcond]).issubset(set(conds))]\n",
    "                    c1_runs = len(cond1_runs)\n",
    "                    c2_runs = len(cond2_runs)\n",
    "                    cond1_columns = [cond1 +'_'+ str(r) for r in cond1_runs]\n",
    "                    cond2_columns = [cond2 +'_'+ str(r) for r in cond2_runs]\n",
    "                    rest1_columns = [restcond +'_'+ str(r) for r in cond1_runs]\n",
    "                    rest2_columns = [restcond +'_'+ str(r) for r in cond2_runs]\n",
    "                    contrast_vals_img [[i for i, col in enumerate(design_matrices_combined.columns) if col in cond1_columns]] +=c2_runs/(c1_runs+c2_runs)\n",
    "                    contrast_vals_img [[i for i, col in enumerate(design_matrices_combined.columns) if col in cond2_columns]] += -1*(c1_runs/(c1_runs+c2_runs))\n",
    "                    contrast_vals_img [[i for i, col in enumerate(design_matrices_combined.columns) if col in rest1_columns]] += -1*(c2_runs/(c1_runs+c2_runs))\n",
    "                    contrast_vals_img [[i for i, col in enumerate(design_matrices_combined.columns) if col in rest2_columns]] += c1_runs/(c1_runs+c2_runs)\n",
    "                    contrasts_sub[cname]= contrast_vals_img\n",
    "    if contrasts_sub:\n",
    "        save_glm_to_bids(fmri_glm_sub, contrasts_sub, out_dir=os.path.join(output_folder, 'subjectLevel', subject), prefix= \"{}_task-{}_run-all\".format(subject, task));\n",
    "        report_sub = make_glm_report(fmri_glm_sub, contrasts_sub, title= 'Statistical report for subject: {} and task: {}'.format(subject, task), alpha =0.001,  bg_img='MNI152TEMPLATE',cluster_threshold=0, height_control='fpr',min_distance=8.0, plot_type='slice', two_sided=True);\n",
    "        report_sub.save_as_html(os.path.join(output_folder, 'subjectLevel', subject, '{}_task-{}_run-all_contrasts-report.html'.format(subject, task)));\n",
    "    if contrasts_runs:\n",
    "        fmri_glm_sub_runs = FirstLevelModel(subject_label='subject', minimize_memory=False) ;\n",
    "        fmri_glm_sub_runs = fmri_glm_sub_runs.fit(bold_files, design_matrices=design_matrices, sample_masks=sample_masks);\n",
    "        save_glm_to_bids(fmri_glm_sub_runs, contrasts_runs, out_dir=os.path.join(output_folder, 'subjectLevel', subject), prefix= \"{}_task-{}\".format(subject, task));\n",
    "        report_sub_runs = make_glm_report(fmri_glm_sub_runs, contrasts_runs, title= 'Statistical report for subject: {} and task: {}'.format(subject, task), alpha =0.001,  bg_img='MNI152TEMPLATE',cluster_threshold=0, height_control='fpr',min_distance=8.0, plot_type='slice', two_sided=True);\n",
    "        report_sub_runs.save_as_html(os.path.join(output_folder, 'subjectLevel', subject, '{}_task-{}_contrasts-report.html'.format(subject, task)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "be867d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a design matrix for each condition and run from this function which is then used then to fit the GLM\n",
    "\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "#from nilearn.interfaces.fmriprep import load_confounds\n",
    "\n",
    "def get_design_matrix(task, subject, run):\n",
    "    json_fname = os.path.join(bids_folder, subject, 'func' ,\"{}_task-{}_run-0{}_bold.json\".format(subject,task, run))\n",
    "    json_file =  open(json_fname)\n",
    "    meta_data=json.load(json_file)\n",
    "    tr = meta_data[\"RepetitionTime\"] # Get the temporal resolution\n",
    "    bold_fname = os.path.join(fmriprep_folder, subject, 'func', \"{}_task-{}_run-0{}_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\".format(subject,task, run))\n",
    "    bold_file = nib.load(bold_fname)\n",
    "    ntp = nib.load(bold_fname).header['dim'][4] # Total number of timepoints in the BOLD data\n",
    "    frame_times = np.arange(0, ntp*tr, tr) # Times in sec in which the fMRI data were acquired\n",
    "    scan_time = ntp*tr \n",
    "    # print(scan_time)\n",
    "\n",
    "    # Extract the stimuli information from the event files\n",
    "    eve_filename= \"{}_task-{}_run-0{}_events.tsv\".format(subject, task, run)\n",
    "    events = pd.read_csv(os.path.join(bids_folder, subject, 'func', eve_filename), sep='\\t')\n",
    "    events = events.loc[:,['onset', 'duration']+[stimcond]]\n",
    "    events=events.rename(columns={stimcond:'trial_type'}) # Change the column of the event condition column to 'trial_type'\n",
    "    # print(\"Events: \", events)\n",
    "\n",
    "    # Get information from the first level confounds to model the nuissance regressors\n",
    "    confounds_path =os.path.join(fmriprep_folder, subject, 'func', '{}_task-{}_run-0{}_desc-confounds_timeseries.tsv'.format(subject, task, run))\n",
    "    if not os.path.isfile(confounds_path):\n",
    "         confounds_path =os.path.join(fmriprep_folder, subject, 'func', '{}_task-{}_run-0{}_desc-confounds_regressors.tsv'.format(subject, task, run))\n",
    "            \n",
    "    confounds  = pd.read_table(confounds_path)\n",
    "    \n",
    "    # Optional way to get nuissance regressors\n",
    "    #confounds,sample_masks = load_confounds(bold_fname, strategy=('motion', 'high_pass','compcor'), motion='basic', scrub=0, fd_threshold=2, \n",
    "    #                                        std_dvars_threshold=5, compcor='anat_combined', n_compcor=6, demean=True)\n",
    "\n",
    "    motion_regs= ['framewise_displacement', 'trans_x', 'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z']\n",
    "    phys_regs = [col for col in confounds if col.startswith('a_comp_cor')]\n",
    "    non_steady_regs = [col for col in confounds if col.startswith('non_steady')]\n",
    "    add_reg_names = motion_regs +phys_regs[0:6] # We only will use the top 6 components\n",
    "    add_regs = confounds.loc[:,add_reg_names].fillna(0).to_numpy()\n",
    "    design_matrix = make_first_level_design_matrix(frame_times,events, hrf_model='spm',\n",
    "                                   drift_model='cosine', high_pass=0.01,\n",
    "                                   add_regs=add_regs, add_reg_names=add_reg_names);\n",
    "\n",
    "   # # saving the design matrix\n",
    "    design_matrix.to_csv(os.path.join(output_folder,'runLevel', subject, \"{}_task-{}_run-0{}_design-full.tsv\".format(subject, task, run)),sep='\\t')\n",
    "   # plot_design_matrix(design_matrix, output_file = os.path.join(output_folder, 'runLevel',subject, '{}_task-{}_run-0{}_design.svg'.format(subject, task, run)))\n",
    "    \n",
    "    \n",
    "    # Save the regressors correlation matrices   \n",
    "\n",
    "    reg_corr = design_matrix.loc[:, design_matrix.columns != \"constant\"].corr().round(2)\n",
    "    sns.set_theme(style=\"white\")\n",
    "    mask = np.triu(np.ones_like(reg_corr, dtype=bool), k=1)  # Generate a mask for the upper triangle\n",
    "    f, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "    # Create the correlation plot heatmap\n",
    "    corrplot = sns.heatmap(reg_corr, mask=mask, cmap='RdBu_r', vmax=1, vmin=-1, center=0,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5, \"format\": \"%.1f\"},annot = True)\n",
    "    corrplot.tick_params(labelsize=15)\n",
    "    plt.savefig(os.path.join(output_folder, 'runLevel', subject, '{}_task-{}_run-0{}_corr.svg'.format(subject,task,run)))\n",
    "    plt.close()\n",
    "    \n",
    "   # Timepoints to include. Currently,include vols with FD less than 2 mm and exclude non steady state outliers\n",
    "    vols_inc = (confounds.loc[:,'framewise_displacement'].fillna(0)< 2) & ~(confounds.loc[:,non_steady_regs].any(axis =1))\n",
    "    sample_mask= np.array([i for i, val in enumerate(vols_inc) if val])\n",
    "                                                                         \n",
    "    return(design_matrix, sample_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "00ee5558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates contrasts within a run for each run. In this case it is condition-rest contrast\n",
    "\n",
    "def create_runLevelContrasts(subject, run, design_matrix, contrast_list):\n",
    "    condition_matrix = np.eye(design_matrix.shape[1])\n",
    "    condition_matrix = {\n",
    "        column: condition_matrix[i]\n",
    "        for i, column in enumerate(design_matrix.columns) if column in conditions\n",
    "    }\n",
    "    contrasts=dict()\n",
    "    for cname in contrast_list:\n",
    "        cond1, cond2 = tuple(cname.split('minus'))\n",
    "        if set(cname.split('minus')).issubset(set(subject_run_conds[subject][runs_avail[subject].index(run)])):\n",
    "            contrasts[cname] = condition_matrix[cond1]- condition_matrix[cond2]\n",
    "    return(contrasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "05af0640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.reporting import make_glm_report\n",
    "from nilearn.interfaces.bids import save_glm_to_bids\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.plotting import plot_contrast_matrix\n",
    "\n",
    "\n",
    "def fitrunmodel (task, subject, run):\n",
    "    design_matrix, sample_mask = get_design_matrix(task, subject,  run);\n",
    "    np.savetxt(os.path.join(output_folder, 'runLevel', subject,\"{}_task-{}_run-0{}_samples.txt\".format(subject, task, run)),  sample_mask , fmt='%d') \n",
    "    fmri_glm = FirstLevelModel(subject_label='{}_run-0{}'.format(subject, run), minimize_memory=False);\n",
    "    print('Fitting a GLM and computing contrasts for subject: {} and run {}'.format(subject, run))\n",
    "    bold_fname = os.path.join(fmriprep_folder, subject, 'func', \"{}_task-{}_run-0{}_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\".format(subject,task, run))\n",
    "    bold_file = nib.load(bold_fname)\n",
    "    fmri_glm = fmri_glm.fit(bold_file, design_matrices=design_matrix, sample_masks=sample_mask);\n",
    "    contrasts = create_runLevelContrasts(subject, run, design_matrix ,contrasts_list);\n",
    "    \n",
    "    # plot the contrast maps\n",
    "    f, ax = plt.subplots(figsize=(20, 6))\n",
    "    contrasts_df = pd.DataFrame.from_dict(contrasts, orient='index', columns = design_matrix.columns)\n",
    "    contrasts_plot = sns.heatmap(contrasts_df, cmap='RdBu_r', vmax=1, vmin=-1, center=0,\n",
    "                     square=True, linewidths=.5, cbar_kws={\"shrink\": 0.5, \"format\": \"%.1f\"},annot = True)\n",
    "    contrasts_plot.tick_params(labelsize=12)\n",
    "    plt.savefig(os.path.join(output_folder, 'runLevel', subject, '{}_task-{}_run-0{}_contrasts.svg'.format(subject, task, run)));\n",
    "    plt.close()\n",
    "\n",
    "    ## Now calculating the contrasts stats\n",
    "    #for contrast_id, contrast_val in contrasts.items(): \n",
    "        # plot_contrast_matrix(contrast_val, design_matrix=design_matrix, output_file=os.path.join(output_folder, 'runLevel', subject,'{}_task-{}_run-0{}_contrast_{}.svg'.format(subject, task, run, contrast_id)))\n",
    "    save_glm_to_bids(fmri_glm, contrasts, out_dir=os.path.join(output_folder, 'runLevel', subject), prefix= \"{}_task-{}_run-0{}\".format(subject, task, run));\n",
    "    report = make_glm_report(fmri_glm, contrasts, title= 'Statistical report for subject: {}, task: {} and run: 0{}'.format(subject, task, run), alpha =0.001,  bg_img='MNI152TEMPLATE',cluster_threshold=0, height_control='fpr',min_distance=8.0, plot_type='slice', two_sided=True);\n",
    "    report.save_as_html(os.path.join(output_folder, 'runLevel', subject, '{}_task-{}_run-0{}_contrasts-report.html'.format(subject, task, run)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "215fe0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will check if any subjects analysis was already completed. if so skips those subjects\n",
    "\n",
    "# Check if subjects completed file exits\n",
    "if (os.path.isfile(os.path.join(output_folder,'Subjects_Completed_{}.txt'.format(task)))):\n",
    "    with open(os.path.join(output_folder,'Subjects_Completed_{}.txt'.format(task))) as f:\n",
    "        subjects_completed = f.readlines()\n",
    "        subjects_completed = [s.strip() for s in subjects_completed if s.strip()]\n",
    "else:\n",
    "    f = open(os.path.join(output_folder,'Subjects_Completed_{}.txt'.format(task)), \"w\")\n",
    "    f.close()\n",
    "    subjects_completed =[]\n",
    "\n",
    "# Create a dictionary so that only subjects who are not previously run are now run\n",
    "subjects_to_run =dict()\n",
    "for s, r in runs_avail.items():\n",
    "    if s not in subjects_completed:\n",
    "        subjects_to_run[s] = r    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "bff839fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the data for subject: sub-blasta001\n",
      "Processing the data for subject: sub-blastc019\n",
      "\n",
      "Processing the data for subject: sub-blasta057\n",
      "Processing the data for subject: sub-blastc213\n",
      "\n",
      "\n",
      "\n",
      "Processing the data for subject: sub-blastc224\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6361f16d4a4305b73dbf31addb7b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66961da121d44e8860d19310b650382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc69cb19ae54dff8daed14c112d8983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e04127293284db5a9d5821d76df2db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c067b2fcaf940d6be5fd8f57b2624fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a GLM and computing contrasts for subject: sub-blastc213 and run 2\n",
      "Fitting a GLM and computing contrasts for subject: sub-blasta057 and run 2\n",
      "Fitting a GLM and computing contrasts for subject: sub-blastc019 and run 1\n",
      "Fitting a GLM and computing contrasts for subject: sub-blastc224 and run 2\n",
      "Fitting a GLM and computing contrasts for subject: sub-blasta001 and run 1\n",
      "Extracting and saving residuals\n",
      "Extracting and saving residuals\n",
      "Extracting and saving residuals\n",
      "Extracting and saving residuals\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n",
      "Extracting and saving r_square\n",
      "Extracting and saving r_square\n",
      "Extracting and saving r_square\n",
      "Extracting and saving r_square\n",
      "Fitting a GLM and computing contrasts for subject: sub-blastc019 and run 2\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n",
      "Fitting a GLM and computing contrasts for subject: sub-blasta057 and run 3\n",
      "Fitting a GLM and computing contrasts for subject: sub-blastc224 and run 3\n",
      "Fitting a GLM and computing contrasts for subject: sub-blastc213 and run 3\n",
      "Extracting and saving residuals\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n",
      "Extracting and saving r_square\n",
      "Fitting a GLM and computing contrasts for subject: sub-blastc019 and run 4\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n",
      "Fitting a GLM and computing contrasts for subject: sub-blastc224 and run 4\n",
      "Fitting a GLM and computing contrasts for subject: sub-blasta001 and run 3\n",
      "Extracting and saving residuals\n",
      "Fitting a GLM and computing contrasts for subject: sub-blastc213 and run 4\n",
      "Fitting a GLM and computing contrasts for subject: sub-blasta057 and run 4\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n",
      "Extracting and saving r_square\n",
      "Extracting and saving residuals\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n",
      "Extracting and saving r_square\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n",
      "Extracting and saving residuals\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n",
      "Extracting and saving r_square\n",
      "Fitting a GLM and computing contrasts for subject: sub-blasta001 and run 4\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n",
      "Extracting and saving residuals\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n",
      "Extracting and saving r_square\n",
      "Extracting and saving residuals\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n",
      "Extracting and saving r_square\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n",
      "Extracting and saving residuals\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n",
      "Extracting and saving r_square\n",
      "Extracting and saving residuals\n",
      "Extracting and saving residuals\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n",
      "Extracting and saving r_square\n",
      "Extracting and saving r_square\n",
      "Extracting and saving residuals\n",
      "Extracting and saving residuals\n",
      "Subject: sub-blasta057 could not be completed due to the exception Unable to allocate 4.85 GiB for an array with shape (78, 93, 71, 1263) and data type float64\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n",
      "Extracting and saving r_square\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n",
      "Extracting and saving residuals\n",
      "Extracting and saving r_square\n"
     ]
    }
   ],
   "source": [
    "#%%capture cap --no-display\n",
    "# Run the analysis for the subjects\n",
    "# Run  subject-level and run-level glm models for subject list\n",
    "import warnings\n",
    "# Use multiprocess rather than multiprocessing, multiprocessing gives an attribute error, see https://stackoverflow.com/questions/41385708/multiprocessing-example-giving-attributeerror\n",
    "from multiprocess.pool import Pool\n",
    "from multiprocess import cpu_count\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from tqdm.notebook import tqdm\n",
    "# Make sure ipywidgets is installed\n",
    "os.makedirs(os.path.join(output_folder,'runLevel'),exist_ok= True)\n",
    "# print(os.path.join(output_folder,'runLevel'))\n",
    "os.makedirs(os.path.join(output_folder,'subjectLevel'),exist_ok= True)\n",
    "pool = Pool(5) #cpu_count()//2) # Using half of all the cpus available to us\n",
    "\n",
    "def run_subject(subject_runs):\n",
    "    subject = subject_runs[0]\n",
    "    runs = subject_runs[1]\n",
    "    try:\n",
    "        print('Processing the data for subject: %s\\n' %(subject))\n",
    "        \n",
    "        # Generate run-level first-level outputs\n",
    "        os.makedirs(os.path.join(output_folder,'runLevel', subject), exist_ok= True)\n",
    "        for run  in tqdm(runs):\n",
    "            design_matrix, sample_mask = get_design_matrix(task, subject, run)\n",
    "            fitrunmodel (task, subject, run);\n",
    "        \n",
    "        # Generate subject-level first-level outputs\n",
    "        os.makedirs(os.path.join(output_folder,'subjectLevel', subject), exist_ok= True)\n",
    "        create_sublevelContrasts(subject, runs, task, contrasts_list_sub);\n",
    "\n",
    "        # Generate a list of subjects whose analyses were completed\n",
    "        f = open(os.path.join(output_folder,'Subjects_Completed_{}.txt'.format(task)), \"a\")\n",
    "        f.write(\"{}\\n\".format(subject))\n",
    "        f.close()\n",
    "    except Exception as error:\n",
    "        print('Subject: %s could not be completed due to the exception %s' %(subject, error))\n",
    "\n",
    "output= pool.map(run_subject, list(subjects_to_run.items()));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189d23f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the contrasts for all subjects on a glass brain just to visualize pattern \n",
    "from nilearn import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "for contrast_id in contrasts_list_sub: \n",
    "    subjects_to_plot = sorted(list(set(runs_avail).intersection(set(map(os.path.basename, glob.glob(os.path.join(output_folder, 'subjectLevel', 'sub-*')))))))\n",
    "    fig, axes = plt.subplots(nrows= math.ceil(len(subjects_to_plot)/5), ncols=5 , squeeze = False)\n",
    "    for i, sub in enumerate(subjects_to_plot):\n",
    "        if contrast_id in contrasts_list:\n",
    "            zmap_path = os.path.join(output_folder, 'subjectLevel', sub, \"{}_task-{}_contrast-{}_stat-z_statmap.nii.gz\".format(sub, task, contrast_id.lower()))\n",
    "        else:\n",
    "            zmap_path = os.path.join(output_folder, 'subjectLevel', sub, \"{}_task-{}_run-all_contrast-{}_stat-z_statmap.nii.gz\".format(sub, task, contrast_id.lower()))\n",
    "            \n",
    "        try:\n",
    "            zmap_img = nilearn.image.load_img(zmap_path)\n",
    "        except ValueError:\n",
    "            zmap_path = os.path.join(output_folder, 'subjectLevel', sub, \"{}_task-{}_contrast-{}_stat-effect_statmap.nii.gz\".format(sub, task, contrast_id.lower()))\n",
    "            zmap_img = nilearn.image.load_img(zmap_path)\n",
    "        finally:\n",
    "            plotting.plot_glass_brain(\n",
    "                zmap_img,\n",
    "                colorbar=False,\n",
    "                threshold=3.0,\n",
    "                title = sub[-3:],\n",
    "                axes=axes[i//5,i% 5],\n",
    "                plot_abs=False,\n",
    "                display_mode='z',\n",
    "            )\n",
    "\n",
    "    fig.suptitle('Subjects(z_map) Contrast: {}'.format(contrast_id))\n",
    "    fig.set_size_inches(20, 15)\n",
    "    [fig.delaxes(ax) for ax in axes.flatten() if not ax.has_data()]\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3033c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
