{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "272e6c55-115d-49cd-ba95-8f3a5cccd6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary python packages for analysis\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import nilearn\n",
    "import string\n",
    "import glob\n",
    "import pathlib\n",
    "import json\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66c80b8b-2cca-457e-b731-e8a369c332e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code downloads MNI pediatric templates if needed\n",
    "\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "from io import BytesIO\n",
    "import re\n",
    "def get_template_file(template=None, extract_to='.', img ='t1w'):\n",
    "    \"\"\"\n",
    "    Downloads and unzips the Pediatric atlases (ZIP files) from the McGill, extracts it, and searches for a specific template file\n",
    "    \n",
    "    Args:\n",
    "    search_filename (str): Filename to search for in the extracted files.\n",
    "    extract_to (str): Directory path where files will be extracted. This is usually the project folder\n",
    "    img (str): type of image to extract, could be 't1w' or 'gm'\n",
    "    Returns:\n",
    "    str: Path to the found template file or a message indicating the file was not found.\n",
    "    \"\"\"\n",
    "    # Send a HTTP request to the URL\n",
    "    # Download the symmetric templates or the assymmetric templates\n",
    "    if 'Asym' in template: \n",
    "        foldname = \"nihpd_asym_all_nifti\" \n",
    "        url = \"https://www.bic.mni.mcgill.ca/~vfonov/nihpd/obj1/nihpd_asym_all_nifti.zip\"\n",
    "        strng = 'asym'\n",
    "    else:\n",
    "        foldname = \"nihpd_sym_all_nifti\" \n",
    "        url = \"https://www.bic.mni.mcgill.ca/~vfonov/nihpd/obj1/nihpd_sym_all_nifti.zip\"\n",
    "        strng = 'sym'\n",
    "        \n",
    "    # Check if the file already exists in the specified folder\n",
    "    \n",
    "    fold_path = os.path.join(extract_to, foldname)\n",
    "    if os.path.exists(fold_path):\n",
    "        print(f\" Template folder already exists: {fold_path}\")\n",
    "    else:\n",
    "        print(f\"File does not exist, downloading from {url}\")\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "        # Open the ZIP file from the bytes-like object\n",
    "            with zipfile.ZipFile(BytesIO(response.content)) as thezip:\n",
    "                # Extract all the contents into the directory specified\n",
    "                thezip.extractall(path=fold_path )\n",
    "                print(f\"Files extracted to {fold_path}\")\n",
    "        else:\n",
    "            return \"Failed to download the template files.\"\n",
    "        \n",
    "    cohort = int(re.search(r'cohort-(\\d+)', template).group(1))\n",
    "    if cohort==1:\n",
    "        search_file =\"nihpd_{}_04.5-18.5_{}.nii\".format(strng, img)\n",
    "    elif cohort==2:\n",
    "        search_file =\"nihpd_{}_04.5-8.5_{}.nii\".format(strng, img)\n",
    "    elif cohort==3:\n",
    "        search_file =\"nihpd_{}_07.0-11.0_{}.nii\".format(strng, img)\n",
    "    elif cohort==4:\n",
    "        search_file =\"nihpd_{}_07.5-13.5_{}.nii\".format(strng, img)\n",
    "    elif cohort==5:\n",
    "        search_file =\"nihpd_{}_10.0-14.0_{}.nii\".format(strng, img)\n",
    "    elif cohort==6:\n",
    "        search_file =\"nihpd_{}_13.0-18.5_{}.nii\".format(strng, img)\n",
    "    else:\n",
    "        search_file =\"nihpd_{}_04.5-18.5_{}.nii\".format(strng, img)\n",
    "\n",
    "        \n",
    "    # Search for a specific template file\n",
    "    for foldername, subfolders, filenames in os.walk(fold_path):\n",
    "        if search_file in filenames:\n",
    "            return os.path.join(foldername, search_file)\n",
    "    return \"Template file not found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1041721b-c026-4170-8df3-2fb814f37c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file paths to access the necessary data\n",
    "\n",
    "project_folder = '/work/qlab_nu/sing_images/blast_adult/' #Set the project folder path \n",
    "fmriprep_folder= os.path.join(project_folder, 'preproc', 'derivatives','fmriprep') # Make sure this folder points to the fMRI prep folder\n",
    "bids_folder= '/work/qlab_nu/NAS_Data/projects/blast/data/bids' # Make sure this folder points to BIDS directory\n",
    "output_folder_main = os.path.join(project_folder, 'preproc', 'derivatives', 'linstats') # This is the folder that saves the first level models\n",
    "os.makedirs(output_folder_main ,exist_ok= True) # Create an output folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8028d5f-dd99-4ce5-a613-3488e913dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the subject IDs of all the subjects available for  analysis\n",
    "\n",
    "task = \"asl\" #Set the task. Should match the BIDS file name\n",
    "\n",
    "no_runs =4 # Max number of runs for each subject\n",
    "restcond = 'rest'\n",
    "stimcond= \"stimcond\"  # THe column in the event file which is used for the modeling the stimuli in the GLM\n",
    "\n",
    "template = 'MNI152NLin2009cAsym' #'MNIPediatricAsym_cohort-4' # Template space could be MNIPediatricAsym or MNI152NLin2009cAsym\n",
    "\n",
    "res =0  # 0 indicates native BOLD resolution\n",
    "\n",
    "if res:\n",
    "    space = '{}_res-{}'.format(template, res)\n",
    "else:\n",
    "    space = template\n",
    "    \n",
    "if  not template:    \n",
    "    template == 'MNI152NLin2009cAsym'\n",
    "    bg_img='MNI152TEMPLATE'\n",
    "    \n",
    "elif 'MNIPediatric' in template:\n",
    "    bg_file = get_template_file(template=template, extract_to=project_folder, img = 't1w')\n",
    "elif 'MNI152' in template:\n",
    "    bg_img='MNI152TEMPLATE'\n",
    "else:\n",
    "    bg_img =None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95a74c51-db9e-4f75-9ca9-f91bd2f93610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: sub-blasta057, run: 1,  event file is empty. Hence this run will be excluded.\n",
      "Subject: sub-blasta071, run: 1,  event file is empty. Hence this run will be excluded.\n"
     ]
    }
   ],
   "source": [
    "# Create the folder that saves the output files\n",
    "output_folder = os.path.join(output_folder_main, task)\n",
    "os.makedirs(output_folder,exist_ok= True)\n",
    "\n",
    "# Search the potential subject names in fMRIprep folder and also the corresponding event files in the BIDS folder\n",
    "potential_sub_list = [pathlib.PurePath(file).name for file in glob.iglob(os.path.join(fmriprep_folder , \"sub-*/\"))]\n",
    "runs_avail= {}\n",
    "scans_avail={}\n",
    "events_avail={}\n",
    "for sub in potential_sub_list:\n",
    "    sub_scan_strng = \"{}_task-{}_run-0[1-{}]_space-{}_desc-preproc_bold.nii.gz\".format(sub,task, no_runs, space)\n",
    "    sub_eve_strng = \"{}_task-{}_run-0[1-{}]_events.tsv\".format(sub,task, no_runs)\n",
    "    scans_avail[sub]= [pathlib.PurePath(file).name for file in glob.iglob(os.path.join(fmriprep_folder, sub,'func', sub_scan_strng))]\n",
    "    events_avail [sub]  = [pathlib.PurePath(file).name for file in glob.iglob(os.path.join(bids_folder, sub, 'func', sub_eve_strng))]\n",
    "    runs_avail[sub] = list(set([int(f.split('_')[2][-1]) for f in scans_avail[sub]]).intersection(set([int(f.split('_')[2][-1]) for f in events_avail[sub]])))\n",
    "        \n",
    "# Lets remove the subjects by removing subjects with no scans\n",
    "scans_avail  = {sub:val for sub, val in scans_avail.items() if val} \n",
    "events_avail = {sub:val for sub, val in runs_avail.items() if val} \n",
    "runs_avail  = {sub:val for sub, val in runs_avail.items() if val} \n",
    "\n",
    "\n",
    "# Lets remove the runs that have lot of timepoints corrupted by motion\n",
    "fd_threshold = 2 # FD threshold in mm\n",
    "removal_threshold = 0.3\n",
    "\n",
    "\n",
    "for subject, runs in runs_avail.items():\n",
    "    runs_remove = []\n",
    "    for run in runs:\n",
    "        json_fname = os.path.join(bids_folder, subject, 'func' ,\"{}_task-{}_run-0{}_bold.json\".format(subject,task, run))\n",
    "        json_file =  open(json_fname)\n",
    "        meta_data=json.load(json_file)\n",
    "        tr = meta_data[\"RepetitionTime\"] # Get the temporal resolution\n",
    "        bold_fname = os.path.join(fmriprep_folder, subject, 'func', \"{}_task-{}_run-0{}_space-{}_desc-preproc_bold.nii.gz\".format(subject,task, run, space))\n",
    "        bold_file = nib.load(bold_fname)\n",
    "        ntp = nib.load(bold_fname).header['dim'][4] # Total number of timepoints in the BOLD data    \n",
    "        eve = pd.read_csv(os.path.join(bids_folder, subject, 'func', '{}_task-{}_run-0{}_events.tsv'.format(subject, task, run)), sep = '\\t')\n",
    "        if not eve.empty:\n",
    "            eve['till'] = eve['onset'] + eve['duration']\n",
    "            vals = np.full(ntp, restcond, dtype=object)\n",
    "            for index, row in eve.iterrows():\n",
    "                vals[int(np.ceil(row['onset']/tr)):int(np.ceil(row['till']/tr))+1] = row[stimcond]\n",
    "\n",
    "            # Get information from the first level confounds to model the nuissance regressors\n",
    "            confounds_path =os.path.join(fmriprep_folder, subject, 'func', '{}_task-{}_run-0{}_desc-confounds_timeseries.tsv'.format(subject, task, run))\n",
    "            if not os.path.isfile(confounds_path):\n",
    "                 confounds_path =os.path.join(fmriprep_folder, subject, 'func', '{}_task-{}_run-0{}_desc-confounds_regressors.tsv'.format(subject, task, run))\n",
    "\n",
    "            confounds  = pd.read_table(confounds_path)\n",
    "            motion_df = pd.DataFrame({'condition': vals ,'fd':confounds['framewise_displacement']})\n",
    "            motion_df = motion_df[motion_df['condition'] != restcond]\n",
    "            motion_df['exclude'] = (motion_df['fd']>fd_threshold).astype(int)\n",
    "            if np.any(motion_df.groupby('condition')['exclude'].agg(['mean']).values>removal_threshold):\n",
    "                print(\"Subject: {}, run: {}, does not have enough data in its conditions to survive >{} data removal. Hence this run will be excluded.\".format(subject, run, removal_threshold))\n",
    "                runs_avail[subject].remove(run)\n",
    "        else:\n",
    "            print(\"Subject: {}, run: {},  event file is empty. Hence this run will be excluded.\".format(subject, run))\n",
    "            runs_remove.append(run)\n",
    "            \n",
    "    runs_avail[subject] = [run for run in runs_avail[subject] if run not in runs_remove]\n",
    "#Further lets remove the scans with empty event files\n",
    "\n",
    "\n",
    "conditions= set()\n",
    "subject_cond = {}# This will have information about conidtions avaialable for each subject across all available runs.\n",
    "everuns_avail={}\n",
    "subject_run_conds = {} # This will save  information about conditions in which run\n",
    "\n",
    "for sub, runs in runs_avail.items():\n",
    "    conds =set()\n",
    "    everuns=[]\n",
    "    conds_run =[]\n",
    "    for run in runs:\n",
    "        eve_filename= \"{}_task-{}_run-0{}_events.tsv\".format(sub, task, run)\n",
    "        events = pd.read_csv(os.path.join(bids_folder, sub, 'func', eve_filename), sep='\\t')\n",
    "        if len(events.index) >0:\n",
    "            everuns.append(run)\n",
    "            conds = conds.union(set(events[stimcond]))\n",
    "            conds_run.append(list(np.unique(events[stimcond])))\n",
    "    everuns_avail[sub]=everuns\n",
    "    subject_cond[sub] = list(conds)\n",
    "    conditions = conditions.union(conds)\n",
    "    subject_run_conds[sub] = conds_run \n",
    "    \n",
    " # Now lets remove the subjects who do not have all the needed conditions in their runs   \n",
    "subject_cond = {subs:conds  for subs, conds in subject_cond.items() if set(conds)==set(conditions)}               \n",
    "runs_avail  = {sub:run for sub, run in runs_avail.items() if run and sub in subject_cond.keys()}\n",
    "subject_run_conds  = {sub:cond for sub, cond in subject_run_conds.items() if sub in subject_cond.keys()}\n",
    "conditions =list(conditions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d091f3f-cd92-4270-86c1-c27f8a6d529e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the task asl the following subjects and runs are available for analyses:\n",
      "sub-blasta001 1 2 3 4\n",
      "sub-blasta002 1 2 3 4\n",
      "sub-blasta004 1 2 3 4\n",
      "sub-blasta005 1 2 3 4\n",
      "sub-blasta006 1 2 3 4\n",
      "sub-blasta007 1 2 3 4\n",
      "sub-blasta008 2 3 4\n",
      "sub-blasta010 1 2 3 4\n",
      "sub-blasta011 1 2 3 4\n",
      "sub-blasta012 1 2 3 4\n",
      "sub-blasta013 1 2 3 4\n",
      "sub-blasta014 1 2 3 4\n",
      "sub-blasta015 1 2 3\n",
      "sub-blasta017 1 2 3 4\n",
      "sub-blasta018 1 2 3 4\n",
      "sub-blasta020 1 2 3 4\n",
      "sub-blasta021 1 2 3 4\n",
      "sub-blasta022 1 2 3 4\n",
      "sub-blasta023 1 2 3 4\n",
      "sub-blasta024 1 2 3 4\n",
      "sub-blasta025 1 2 3 4\n",
      "sub-blasta026 1 2 3\n",
      "sub-blasta027 1 2 3 4\n",
      "sub-blasta028 1 2 3 4\n",
      "sub-blasta029 1 2 3 4\n",
      "sub-blasta032 1 2 3 4\n",
      "sub-blasta035 1 2 3 4\n",
      "sub-blasta038 1 2 3 4\n",
      "sub-blasta039 1 2 3 4\n",
      "sub-blasta040 1 2 3 4\n",
      "sub-blasta044 1 2 3 4\n",
      "sub-blasta054 1 2 3 4\n",
      "sub-blasta055 1 2 3 4\n",
      "sub-blasta056 1 2 3 4\n",
      "sub-blasta057 2 3 4\n",
      "sub-blasta058 1 2 3 4\n",
      "sub-blasta060 1 2 3 4\n",
      "sub-blasta069 1 2 3 4\n",
      "sub-blasta071 2 3\n",
      "sub-blasta075 1 2 3 4\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to remove any subjects? Y or N Y\n",
      "Do you have a file that removes that list subjects that you want to use? Y or N N\n",
      "Input a list of subjects you want removed and seperate each subject seperated by commas sub-blasta057, sub-blasta071\n",
      "Do you want to remove any subjects? Y or N N\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the task asl the final list of subjects and runs will be used for analyses:\n",
      "sub-blasta001 1 2 3 4\n",
      "sub-blasta002 1 2 3 4\n",
      "sub-blasta004 1 2 3 4\n",
      "sub-blasta005 1 2 3 4\n",
      "sub-blasta006 1 2 3 4\n",
      "sub-blasta007 1 2 3 4\n",
      "sub-blasta008 2 3 4\n",
      "sub-blasta010 1 2 3 4\n",
      "sub-blasta011 1 2 3 4\n",
      "sub-blasta012 1 2 3 4\n",
      "sub-blasta013 1 2 3 4\n",
      "sub-blasta014 1 2 3 4\n",
      "sub-blasta015 1 2 3\n",
      "sub-blasta017 1 2 3 4\n",
      "sub-blasta018 1 2 3 4\n",
      "sub-blasta020 1 2 3 4\n",
      "sub-blasta021 1 2 3 4\n",
      "sub-blasta022 1 2 3 4\n",
      "sub-blasta023 1 2 3 4\n",
      "sub-blasta024 1 2 3 4\n",
      "sub-blasta025 1 2 3 4\n",
      "sub-blasta026 1 2 3\n",
      "sub-blasta027 1 2 3 4\n",
      "sub-blasta028 1 2 3 4\n",
      "sub-blasta029 1 2 3 4\n",
      "sub-blasta032 1 2 3 4\n",
      "sub-blasta035 1 2 3 4\n",
      "sub-blasta038 1 2 3 4\n",
      "sub-blasta039 1 2 3 4\n",
      "sub-blasta040 1 2 3 4\n",
      "sub-blasta044 1 2 3 4\n",
      "sub-blasta054 1 2 3 4\n",
      "sub-blasta055 1 2 3 4\n",
      "sub-blasta056 1 2 3 4\n",
      "sub-blasta058 1 2 3 4\n",
      "sub-blasta060 1 2 3 4\n",
      "sub-blasta069 1 2 3 4\n",
      "sub-blasta075 1 2 3 4\n"
     ]
    }
   ],
   "source": [
    "# Now lets print the subject list and runs avaiable forthe task analysis\n",
    "import copy\n",
    "print(\"For the task\",task, \"the following subjects and runs are available for analyses:\")\n",
    "for sub, runs in runs_avail.items():\n",
    "    print(sub, ' '.join(map(str ,runs)))\n",
    "    \n",
    "final_subject_list = copy.deepcopy(runs_avail)\n",
    "R1 = 'y'\n",
    "while R1.lower()=='y':\n",
    "    R1 = input(\"Do you want to remove any subjects? Y or N\")\n",
    "    if R1.lower()=='y':\n",
    "        R2 = input(\"Do you have a file that removes that list subjects that you want to use? Y or N\")\n",
    "        if R2.lower() =='y':\n",
    "            R3= input(\"Input the path of the file\")\n",
    "            sub_removal_list = pd.read_csv(R3)\n",
    "            sub_removal =sub_removal_list.loc[sub_removal_list['remove'].astype(bool), ['part_id', 'run']]\n",
    "            for i,row in sub_removal.iterrows():\n",
    "                final_subject_list['sub-'+row['part_id'].replace('_', '')].remove(row['run'])\n",
    "            \n",
    "        else:\n",
    "            subs= input(\"Input a list of subjects you want removed and seperate each subject seperated by commas\")\n",
    "            subs = subs.split(\", \")\n",
    "            for s in subs:\n",
    "                if s in final_subject_list.keys():\n",
    "                    del final_subject_list[s]\n",
    "                    \n",
    "    elif R1.lower()=='n':\n",
    "        break;\n",
    "    else:\n",
    "        print(\"Please enter either Y or N as valid output\")\n",
    "        R1='y'\n",
    "        \n",
    "print(\"For the task\",task, \"the final list of subjects and runs will be used for analyses:\")\n",
    "\n",
    "for sub, runs in final_subject_list.items():\n",
    "    print(sub, ' '.join(map(str ,runs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f93d161-b764-4f87-ba11-2a6a54798bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a list of contasts to be calculated. Contrasts should be in the format of cond1minuscond2. If  all entered press Enter syllableSminusrest\n",
      "Enter a list of contasts to be calculated. Contrasts should be in the format of cond1minuscond2. If  all entered press Enter syllableRminusrest\n",
      "Enter a list of contasts to be calculated. Contrasts should be in the format of cond1minuscond2. If  all entered press Enter toneSminusrest\n",
      "Enter a list of contasts to be calculated. Contrasts should be in the format of cond1minuscond2. If  all entered press Enter toneRminusrest\n",
      "Enter a list of contasts to be calculated. Contrasts should be in the format of cond1minuscond2. If  all entered press Enter \n"
     ]
    }
   ],
   "source": [
    "# Estimate run level contrasts\n",
    "from itertools import chain\n",
    "def check_contrast_run(cont):\n",
    "    unq_cond_runs = [list(x) for x in set(tuple(x) for x in list(chain.from_iterable(subject_run_conds.values())))]\n",
    "    return (any([set(cont.split(\"minus\")).issubset(set(cond)) for cond in unq_cond_runs]))\n",
    "\n",
    "contrasts_list = list()\n",
    "while True:\n",
    "    cont = input(\"Enter a list of contasts to be calculated. Contrasts should be in the format of cond1minuscond2. If  all entered press Enter\")\n",
    "    if cont:\n",
    "        if (check_contrast_run(cont) and len(cont.split(\"minus\"))==2):\n",
    "            contrasts_list.append(cont)\n",
    "        else:\n",
    "            print(\"Contrast not valid. Enter a valid string.\")\n",
    "    else:\n",
    "        break\n",
    "contrasts_list = list(set(contrasts_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c67f8150-6200-4834-b49e-1117fb056fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrasts that will be calculated at subject level:\n",
      "syllableSminusrest\n",
      "toneSminusrest\n",
      "syllableRminusrest\n",
      "toneRminusrest\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a list of additional contrasts to be calculated at subject level. Contrasts should be in the format of cond1minuscond2. If  all entered press Enter syllableSminussyllableR\n",
      "Enter a list of additional contrasts to be calculated at subject level. Contrasts should be in the format of cond1minuscond2. If  all entered press Enter toneSminustoneR\n",
      "Enter a list of additional contrasts to be calculated at subject level. Contrasts should be in the format of cond1minuscond2. If  all entered press Enter \n"
     ]
    }
   ],
   "source": [
    "#Estimate subject level contrasts\n",
    "import copy\n",
    "contrasts_list_sub = copy.deepcopy(contrasts_list)\n",
    "print(\"Contrasts that will be calculated at subject level:\")\n",
    "for c in contrasts_list_sub:\n",
    "    print(c)\n",
    "while True:\n",
    "    cont = input(\"Enter a list of additional contrasts to be calculated at subject level. Contrasts should be in the format of cond1minuscond2. If  all entered press Enter\")\n",
    "    if cont:\n",
    "        if (set(cont.split(\"minus\")).issubset(set(conditions)) and len(cont.split(\"minus\"))==2):\n",
    "            contrasts_list_sub.append(cont)\n",
    "        else:\n",
    "            print(\"Contrast not valid. Enter a valid string.\")\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "contrasts_list_sub = list(set(contrasts_list_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "220a774d-56d6-44e7-acf4-421d5d631756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define subject level contrasts. Here the contrasts are calculated across the multiple runs. So we calculate c\n",
    "import re\n",
    "from nilearn.glm.contrasts import compute_fixed_effects\n",
    "from nilearn.image import concat_imgs\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.interfaces.bids import save_glm_to_bids\n",
    "from nilearn.reporting import make_glm_report\n",
    "import copy\n",
    "def estimate_subject_stats (subject, task, contrast, effect_files_list, var_files_list, template = None):\n",
    "    contrast_imgs = list(map(nib.load, effect_files_list))\n",
    "    variance_imgs = list(map(nib.load, var_files_list))   \n",
    "    \n",
    "    if template:    \n",
    "        if 'MNIPediatric' in template:\n",
    "            mask_img = nib.load(get_template_file(template=template, extract_to=project_folder, img = 'gm'))\n",
    "            mask_data = mask_img.get_fdata()\n",
    "            mask_data = (mask_data>0.2).astype(int)\n",
    "            mask_img = nib.Nifti1Image(mask_data, header=mask_img.header, affine=mask_img.affine)\n",
    "        elif 'MNI152' in template:\n",
    "            mask_img = nilearn.datasets.fetch_icbm152_brain_gm_mask()\n",
    "        else:\n",
    "            mask_img = None\n",
    "    else:\n",
    "        mask_img = nilearn.datasets.fetch_icbm152_brain_gm_mask()\n",
    "\n",
    "    #  fixed effects modeling without precision_weighting\n",
    "    fixed_fx_contrast_img,fixed_fx_variance_img, fixed_fx_t_img, fixed_fx_z_score_img = compute_fixed_effects(contrast_imgs, variance_imgs, mask= mask_img, precision_weighted=False, return_z_score=True)\n",
    "    fixed_fx_contrast_img.to_filename(os.path.join(output_folder, 'subjectLevel', subject, \"{}_task-{}_space-{}_contrast-{}_stat-effect_statmap.nii.gz\".format(subject, task,  space, contrast)))\n",
    "    fixed_fx_variance_img.to_filename(os.path.join(output_folder, 'subjectLevel', subject, \"{}_task-{}_space-{}_contrast-{}_stat-variance_statmap.nii.gz\".format(subject, task, space, contrast )))\n",
    "    fixed_fx_t_img.to_filename(os.path.join(output_folder, 'subjectLevel', subject, \"{}_task-{}_space-{}_contrast-{}_stat-t_statmap.nii.gz\".format(subject, task, space, contrast)))\n",
    "    fixed_fx_z_score_img.to_filename(os.path.join(output_folder, 'subjectLevel', subject, \"{}_task-{}_space-{}_contrast-{}_stat-zscore_statmap.nii.gz\".format(subject, task, space, contrast )))\n",
    "    \n",
    "def create_sublevelContrasts(subject, runs, task, contrasts_list_sub, template = None):\n",
    "    design_matrices_list=  glob.glob(os.path.join(output_folder,'runLevel', subject, \"{}_task-{}_run-0{}_design-full.tsv\".format(subject, task, runs)))\n",
    "    design_matrices = [pd.read_csv(file, sep=\"\\t\" ) for file in design_matrices_list]\n",
    "    design_matrices = [ds.drop(columns= 'Unnamed: 0') for ds in design_matrices]                                        \n",
    "    for i, run in enumerate(runs):\n",
    "        design_matrices[i].columns =  [col+'_'+ str(run) for col in design_matrices[i].columns]\n",
    "        if i>0:\n",
    "            design_matrices[i].index += design_matrices[i-1].index[-1] + 1\n",
    "    design_matrices_combined = pd.concat(design_matrices)\n",
    "    design_matrices_combined.fillna(0, inplace=True)\n",
    "    for r in range(no_runs):\n",
    "        design_matrices_combined.rename(columns={'constant_{}'.format(r): 'run_{}'.format(r)}, inplace =True, errors = 'ignore')\n",
    "    design_matrices_combined['constant']=1\n",
    "    design_matrices_combined.to_csv(os.path.join(output_folder,'subjectLevel', subject, \"{}_task-{}_design.tsv\".format(subject, task)),sep='\\t')                                    \n",
    "    bold_files_list = glob.glob(os.path.join(fmriprep_folder, subject, 'func', \"{}_task-{}_run-0{}_space-{}_desc-preproc_bold.nii.gz\".format(subject,task, runs, space)))\n",
    "    bold_files = list(map(nib.load, bold_files_list))\n",
    "    bold_data_combined = concat_imgs(bold_files)\n",
    "    samples_files_list= glob.glob(os.path.join(output_folder,'runLevel', subject, \"{}_task-{}_run-0{}_samples.txt\".format(subject, task, runs)))\n",
    "    sample_masks =[np.loadtxt(file, dtype='int') for file in samples_files_list]\n",
    "    sample_masks_combined = copy.deepcopy(sample_masks)\n",
    "    for i, run in enumerate(runs):\n",
    "        sample_masks_combined[i] += i*bold_files[i-1].shape[3] \n",
    "    sample_masks_combined = np.concatenate(sample_masks_combined).ravel()\n",
    "    np.savetxt(os.path.join(output_folder, 'subjectLevel', subject,\"{}_task-{}_samples.txt\".format(subject, task)),  sample_masks_combined , fmt='%d')                               \n",
    "    fmri_glm_sub = FirstLevelModel(subject_label='subject', minimize_memory=False);\n",
    "    fmri_glm_sub = fmri_glm_sub.fit(bold_data_combined , design_matrices=design_matrices_combined, sample_masks=sample_masks_combined);\n",
    "    contrasts_sub = dict()\n",
    "    contrasts_runs = dict()\n",
    "    for cname in contrasts_list_sub:\n",
    "            cond1, cond2 = tuple(cname.split('minus'))\n",
    "            if set(cname.split('minus')).issubset(subject_cond[subject]):\n",
    "                runs_cont = [runs_avail[subject][idx] for idx, conds in enumerate(subject_run_conds[subject]) if set(cname.split('minus')).issubset(set(conds))]\n",
    "                \n",
    "                if runs_cont:\n",
    "                    design_matrices_list_cont=  glob.glob(os.path.join(output_folder,'runLevel', subject, \"{}_task-{}_run-0{}_design-full.tsv\".format(subject, task, runs_cont)))\n",
    "                    design_matrices_cont = [pd.read_csv(file, sep=\"\\t\" ) for file in design_matrices_list_cont]\n",
    "                    design_matrices_cont = [ds.drop(columns= 'Unnamed: 0') for ds in design_matrices_cont] \n",
    "                    if (runs_cont== runs) and (all([len(ds.columns) for ds in design_matrices_cont])) and (all([set(design_matrices_cont[0].columns)==r for r in [set(ds.columns) for ds in design_matrices_cont[1:]]])):\n",
    "                        condition_matrix_cont = np.eye(design_matrices_cont[0].shape[1])\n",
    "                        condition_matrix_cont = {\n",
    "                        column: condition_matrix_cont[i]\n",
    "                        for i, column in enumerate(design_matrices_cont[0].columns) if column in conditions\n",
    "                        }\n",
    "                        contrasts_runs[cname] = condition_matrix_cont[cond1]- condition_matrix_cont[cond2]\n",
    "                    else:\n",
    "\n",
    "                        if (all([len(ds.columns) for ds in design_matrices_cont])) and (all([set(design_matrices_cont[0].columns)==r for r in [set(ds.columns) for ds in design_matrices_cont[1:]]])):\n",
    "                         # This part of the code is run if the columns of the design matrix are same across different runs \n",
    "                            bold_files_list_cont = glob.glob(os.path.join(fmriprep_folder, subject, 'func', \"{}_task-{}_run-0{}_space-{}_desc-preproc_bold.nii.gz\".format(subject,task, runs_cont, space)))\n",
    "                            bold_files_cont = list(map(nib.load, bold_files_list_cont))\n",
    "\n",
    "                            samples_files_list_cont= glob.glob(os.path.join(output_folder,'runLevel', subject, \"{}_task-{}_run-0{}_samples.txt\".format(subject, task, runs_cont)))\n",
    "                            sample_masks_cont =[np.loadtxt(file, dtype='int') for file in samples_files_list_cont]\n",
    "                            fmri_glm_sub_cont = FirstLevelModel(subject_label='subject', minimize_memory=False) ;\n",
    "                            fmri_glm_sub_cont = fmri_glm_sub_cont.fit(bold_files_cont, design_matrices=design_matrices_cont, sample_masks=sample_masks_cont);\n",
    "                            condition_matrix_cont = np.eye(design_matrices_cont[0].shape[1])\n",
    "                            condition_matrix_cont = {\n",
    "                            column: condition_matrix_cont[i]\n",
    "                            for i, column in enumerate(design_matrices_cont[0].columns) if column in conditions\n",
    "                            }\n",
    "                            contrasts=dict()\n",
    "                            contrasts[cname] = condition_matrix_cont[cond1]- condition_matrix_cont[cond2]\n",
    "                            save_glm_to_bids(fmri_glm_sub_cont, contrasts, out_dir=os.path.join(output_folder, 'subjectLevel', subject), prefix= \"{}_task-{}_space-{}\".format(subject, task, space))\n",
    "                            report_sub_cont = make_glm_report(fmri_glm_sub_cont, contrasts, title= 'Statistical report for subject: {} and task: {}'.format(subject, task), alpha =0.001,  bg_img=bg_img, cluster_threshold=0, height_control='fpr',min_distance=8.0, plot_type='slice', two_sided=True);\n",
    "                            report_sub_cont.save_as_html(os.path.join(output_folder, 'subjectLevel', subject, '{}_task-{}_space-{}_contrast-{}_contrasts-report.html'.format(subject, task, space, cname.lower())));\n",
    "\n",
    "                        else:\n",
    "                             # This part of the code is run if the columns of the design matrix are not same across runs, either due to different nuissance regressors.\n",
    "                            effect_files_list = glob.glob(os.path.join(output_folder, 'runLevel', subject, \"{}_task-{}_space-{}_run-0[0-9]_contrast-{}_stat-effect_statmap.nii.gz\".format(subject, task, space, cname.lower())))\n",
    "                            var_files_list = glob.glob(os.path.join(output_folder, 'runLevel', subject, \"{}_task-{}_space-{}_run-0[0-9]_contrast-{}_stat-variance_statmap.nii.gz\".format(subject, task, space, cname.lower())))\n",
    "                            cstring = os.path.basename(effect_files_list[0])\n",
    "                            contrast = re.search(r\"contrast-[a-z]+\", cstring).group().split('-')[1]                            \n",
    "                            estimate_subject_stats (subject, task, contrast.lower(), effect_files_list, var_files_list, template)\n",
    "                            \n",
    "                elif (set(cname.split('minus')+[restcond]).issubset(subject_cond[subject])):          \n",
    "                    contrast_vals_img = np.zeros(design_matrices_combined.shape[1])\n",
    "                    cond1_runs = [runs_avail[subject][idx] for idx, conds in enumerate(subject_run_conds[subject]) if set([cond1,restcond]).issubset(set(conds))]\n",
    "                    cond2_runs = [runs_avail[subject][idx] for idx, conds in enumerate(subject_run_conds[subject]) if set([cond2,restcond]).issubset(set(conds))]\n",
    "                    c1_runs = len(cond1_runs)\n",
    "                    c2_runs = len(cond2_runs)\n",
    "                    cond1_columns = [cond1 +'_'+ str(r) for r in cond1_runs]\n",
    "                    cond2_columns = [cond2 +'_'+ str(r) for r in cond2_runs]\n",
    "                    rest1_columns = [restcond +'_'+ str(r) for r in cond1_runs]\n",
    "                    rest2_columns = [restcond +'_'+ str(r) for r in cond2_runs]\n",
    "                    contrast_vals_img [[i for i, col in enumerate(design_matrices_combined.columns) if col in cond1_columns]] +=c2_runs/(c1_runs+c2_runs)\n",
    "                    contrast_vals_img [[i for i, col in enumerate(design_matrices_combined.columns) if col in cond2_columns]] += -1*(c1_runs/(c1_runs+c2_runs))\n",
    "                    contrast_vals_img [[i for i, col in enumerate(design_matrices_combined.columns) if col in rest1_columns]] += -1*(c2_runs/(c1_runs+c2_runs))\n",
    "                    contrast_vals_img [[i for i, col in enumerate(design_matrices_combined.columns) if col in rest2_columns]] += c1_runs/(c1_runs+c2_runs)\n",
    "                    contrasts_sub[cname]= contrast_vals_img\n",
    "                    \n",
    "    if contrasts_sub:\n",
    "        save_glm_to_bids(fmri_glm_sub, contrasts_sub, out_dir=os.path.join(output_folder, 'subjectLevel', subject), prefix= \"{}_task-{}_space-{}_run-all\".format(subject, task, space));\n",
    "        report_sub = make_glm_report(fmri_glm_sub, contrasts_sub, title= 'Statistical report for subject: {} and task: {}'.format(subject, task), alpha =0.001,  bg_img=bg_img, cluster_threshold=0, height_control='fpr',min_distance=8.0, plot_type='slice', two_sided=True);\n",
    "        report_sub.save_as_html(os.path.join(output_folder, 'subjectLevel', subject, '{}_task-{}_space-{}_run-all_contrasts-report.html'.format(subject, task, space)));\n",
    "    if contrasts_runs:\n",
    "        fmri_glm_sub_runs = FirstLevelModel(subject_label='subject', minimize_memory=False) ;\n",
    "        fmri_glm_sub_runs = fmri_glm_sub_runs.fit(bold_files, design_matrices=design_matrices, sample_masks=sample_masks);\n",
    "        save_glm_to_bids(fmri_glm_sub_runs, contrasts_runs, out_dir=os.path.join(output_folder, 'subjectLevel', subject), prefix= \"{}_task-{}_space-{}\".format(subject, task, space));\n",
    "        report_sub_runs = make_glm_report(fmri_glm_sub_runs, contrasts_runs, title= 'Statistical report for subject: {} and task: {}'.format(subject, task), alpha =0.001,  bg_img=bg_img, cluster_threshold=0, height_control='fpr',min_distance=8.0, plot_type='slice', two_sided=True);\n",
    "        report_sub_runs.save_as_html(os.path.join(output_folder, 'subjectLevel', subject, '{}_task-{}_space-{}_contrasts-report.html'.format(subject, task, space)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6227721-539b-4bdd-9f2f-cd7699aceae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a design matrix for each condition and run from this function which is then used then to fit the GLM\n",
    "\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "#from nilearn.interfaces.fmriprep import load_confounds\n",
    "\n",
    "def get_design_matrix(task, subject, run):\n",
    "    json_fname = os.path.join(bids_folder, subject, 'func' ,\"{}_task-{}_run-0{}_bold.json\".format(subject,task, run))\n",
    "    json_file =  open(json_fname)\n",
    "    meta_data=json.load(json_file)\n",
    "    tr = meta_data[\"RepetitionTime\"] # Get the temporal resolution\n",
    "    bold_fname = os.path.join(fmriprep_folder, subject, 'func', \"{}_task-{}_run-0{}_space-{}_desc-preproc_bold.nii.gz\".format(subject,task, run, space))\n",
    "    bold_file = nib.load(bold_fname)\n",
    "    ntp = nib.load(bold_fname).header['dim'][4] # Total number of timepoints in the BOLD data\n",
    "    frame_times = np.arange(0, ntp*tr, tr) # Times in sec in which the fMRI data were acquired\n",
    "    scan_time = ntp*tr \n",
    "\n",
    "    # Extract the stimuli information from the event files\n",
    "    eve_filename= \"{}_task-{}_run-0{}_events.tsv\".format(subject, task, run)\n",
    "    events = pd.read_csv(os.path.join(bids_folder, subject, 'func', eve_filename), sep='\\t')\n",
    "    events = events.loc[:,['onset', 'duration']+[stimcond]]\n",
    "    events=events.rename(columns={stimcond:'trial_type'}) # Change the column of the event condition column to 'trial_type'\n",
    "\n",
    "    # Get information from the first level confounds to model the nuissance regressors\n",
    "    confounds_path =os.path.join(fmriprep_folder, subject, 'func', '{}_task-{}_run-0{}_desc-confounds_timeseries.tsv'.format(subject, task, run))\n",
    "    if not os.path.isfile(confounds_path):\n",
    "         confounds_path =os.path.join(fmriprep_folder, subject, 'func', '{}_task-{}_run-0{}_desc-confounds_regressors.tsv'.format(subject, task, run))\n",
    "            \n",
    "    confounds  = pd.read_table(confounds_path)\n",
    "    \n",
    "    # Optional way to get nuissance regressors\n",
    "    #confounds,sample_masks = load_confounds(bold_fname, strategy=('motion', 'high_pass','compcor'), motion='basic', scrub=0, fd_threshold=2, \n",
    "    #                                        std_dvars_threshold=5, compcor='anat_combined', n_compcor=6, demean=True)\n",
    "\n",
    "    motion_regs= ['framewise_displacement', 'trans_x', 'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z']\n",
    "    phys_regs = [col for col in confounds if col.startswith('a_comp_cor')]\n",
    "    non_steady_regs = [col for col in confounds if col.startswith('non_steady')]\n",
    "    add_reg_names = motion_regs +phys_regs[0:6] # We only will use the top 6 components\n",
    "    add_regs = confounds.loc[:,add_reg_names].fillna(0).to_numpy()\n",
    "    design_matrix = make_first_level_design_matrix(frame_times,events, hrf_model='spm',\n",
    "                                   drift_model='cosine', high_pass=0.01,\n",
    "                                   add_regs=add_regs, add_reg_names=add_reg_names);\n",
    "\n",
    "   # # saving the design matrix\n",
    "    design_matrix.to_csv(os.path.join(output_folder,'runLevel', subject, \"{}_task-{}_run-0{}_design-full.tsv\".format(subject, task, run)),sep='\\t')\n",
    "   # plot_design_matrix(design_matrix, output_file = os.path.join(output_folder, 'runLevel',subject, '{}_task-{}_run-0{}_design.svg'.format(subject, task, run)))\n",
    "    \n",
    "    \n",
    "    # Save the regressors correlation matrices   \n",
    "\n",
    "    reg_corr = design_matrix.loc[:, design_matrix.columns != \"constant\"].corr().round(2)\n",
    "    sns.set_theme(style=\"white\")\n",
    "    mask = np.triu(np.ones_like(reg_corr, dtype=bool), k=1)  # Generate a mask for the upper triangle\n",
    "    f, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "    # Create the correlation plot heatmap\n",
    "    corrplot = sns.heatmap(reg_corr, mask=mask, cmap='RdBu_r', vmax=1, vmin=-1, center=0,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5, \"format\": \"%.1f\"},annot = True)\n",
    "    corrplot.tick_params(labelsize=15)\n",
    "    plt.savefig(os.path.join(output_folder, 'runLevel', subject, '{}_task-{}_run-0{}_corr.svg'.format(subject,task,run)))\n",
    "    plt.close()\n",
    "    \n",
    "   # Timepoints to include. Currently,include vols with FD less than 2 mm and exclude non steady state outliers\n",
    "    vols_inc = (confounds.loc[:,'framewise_displacement'].fillna(0)< fd_threshold) & ~(confounds.loc[:,non_steady_regs].any(axis =1))\n",
    "    sample_mask= np.array([i for i, val in enumerate(vols_inc) if val])\n",
    "                                                                         \n",
    "    return(design_matrix, sample_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55a32f4d-1495-44b4-8b2c-e26a337bf62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates contrasts within a run for each run. In this case it is condition-rest contrast\n",
    "\n",
    "def create_runLevelContrasts(subject, run, design_matrix, contrast_list):\n",
    "    condition_matrix = np.eye(design_matrix.shape[1])\n",
    "    condition_matrix = {\n",
    "        column: condition_matrix[i]\n",
    "        for i, column in enumerate(design_matrix.columns) if column in conditions\n",
    "    }\n",
    "    contrasts=dict()\n",
    "    for cname in contrast_list:\n",
    "        cond1, cond2 = tuple(cname.split('minus'))\n",
    "        if set(cname.split('minus')).issubset(set(subject_run_conds[subject][runs_avail[subject].index(run)])):\n",
    "            contrasts[cname] = condition_matrix[cond1]- condition_matrix[cond2]\n",
    "    return(contrasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08d17473-1f2e-4da2-a017-413625429b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.reporting import make_glm_report\n",
    "from nilearn.interfaces.bids import save_glm_to_bids\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.plotting import plot_contrast_matrix\n",
    "\n",
    "\n",
    "def fitrunmodel (task, subject, run):\n",
    "    design_matrix, sample_mask = get_design_matrix(task, subject,  run);\n",
    "    np.savetxt(os.path.join(output_folder, 'runLevel', subject,\"{}_task-{}_run-0{}_samples.txt\".format(subject, task, run)),  sample_mask , fmt='%d') \n",
    "    fmri_glm = FirstLevelModel(subject_label='{}_run-0{}'.format(subject, run), minimize_memory=False);\n",
    "    #print('Fitting a GLM and computing contrasts for subject: {} and run {}'.format(subject, run))\n",
    "    bold_fname = os.path.join(fmriprep_folder, subject, 'func', \"{}_task-{}_run-0{}_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\".format(subject,task, run))\n",
    "    bold_file = nib.load(bold_fname)\n",
    "    fmri_glm = fmri_glm.fit(bold_file, design_matrices=design_matrix, sample_masks=sample_mask);\n",
    "    contrasts = create_runLevelContrasts(subject, run, design_matrix ,contrasts_list);\n",
    "    \n",
    "    # plot the contrast maps\n",
    "    f, ax = plt.subplots(figsize=(20, 6))\n",
    "    contrasts_df = pd.DataFrame.from_dict(contrasts, orient='index', columns = design_matrix.columns)\n",
    "    contrasts_plot = sns.heatmap(contrasts_df, cmap='RdBu_r', vmax=1, vmin=-1, center=0,\n",
    "                     square=True, linewidths=.5, cbar_kws={\"shrink\": 0.5, \"format\": \"%.1f\"},annot = True)\n",
    "    contrasts_plot.tick_params(labelsize=12)\n",
    "    plt.savefig(os.path.join(output_folder, 'runLevel', subject, '{}_task-{}_run-0{}_contrasts.svg'.format(subject, task, run)));\n",
    "    plt.close()\n",
    "\n",
    "    ## Now calculating the contrasts stats\n",
    "    #for contrast_id, contrast_val in contrasts.items(): \n",
    "        # plot_contrast_matrix(contrast_val, design_matrix=design_matrix, output_file=os.path.join(output_folder, 'runLevel', subject,'{}_task-{}_run-0{}_contrast_{}.svg'.format(subject, task, run, contrast_id)))\n",
    "    save_glm_to_bids(fmri_glm, contrasts, out_dir=os.path.join(output_folder, 'runLevel', subject), prefix= \"{}_task-{}_run-0{}\".format(subject, task, run));\n",
    "    report = make_glm_report(fmri_glm, contrasts, title= 'Statistical report for subject: {}, task: {} and run: 0{}'.format(subject, task, run), alpha =0.001,  bg_img= bg_img,cluster_threshold=0, height_control='fpr',min_distance=8.0, plot_type='slice', two_sided=True);\n",
    "    report.save_as_html(os.path.join(output_folder, 'runLevel', subject, '{}_task-{}_run-0{}_contrasts-report.html'.format(subject, task, run)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57f432e7-ed25-4f2e-a3a1-0c3b276db53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will check if any subjects analysis was already completed. if so skips those subjects\n",
    "\n",
    "# Check if subjects completed file exits\n",
    "if (os.path.isfile(os.path.join(output_folder,'Subjects_Completed_{}_{}.txt'.format(task, template)))):\n",
    "    with open(os.path.join(output_folder,'Subjects_Completed_{}_{}.txt'.format(task, template))) as f:\n",
    "        subjects_completed = f.readlines()\n",
    "        subjects_completed = [s.strip() for s in subjects_completed if s.strip()]\n",
    "else:\n",
    "    f = open(os.path.join(output_folder,'Subjects_Completed_{}_{}.txt'.format(task, template)), \"w\")\n",
    "    f.close()\n",
    "    subjects_completed =[]\n",
    "\n",
    "# Create a dictionary so that only subjects who are not previously run are now run\n",
    "subjects_to_run =dict()\n",
    "for s, r in final_subject_list.items():\n",
    "    if s not in subjects_completed:\n",
    "        subjects_to_run[s] = r  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e93e0a-beb1-49fc-aa39-18fffbc64a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from contextlib import contextmanager\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Setup the logger\n",
    "logging.basicConfig(filename=os.path.join(output_folder, 'output.log'), level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Capture warnings with logging\n",
    "logging.captureWarnings(True)\n",
    "\n",
    "@contextmanager\n",
    "def log_redirect():\n",
    "    class StreamToLogger:\n",
    "        def __init__(self, logger, log_level=logging.INFO):\n",
    "            self.logger = logger\n",
    "            self.log_level = log_level\n",
    "            self.linebuf = ''\n",
    "\n",
    "        def write(self, buf):\n",
    "            for line in buf.rstrip().splitlines():\n",
    "                self.logger.log(self.log_level, line.rstrip())\n",
    "\n",
    "        def flush(self):\n",
    "            pass\n",
    "\n",
    "    old_stdout = sys.stdout\n",
    "    old_stderr = sys.stderr\n",
    "    logger = logging.getLogger()\n",
    "    sys.stdout = StreamToLogger(logger, logging.INFO)\n",
    "    sys.stderr = StreamToLogger(logger, logging.ERROR)\n",
    "\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        sys.stdout = old_stdout\n",
    "        sys.stderr = old_stderr\n",
    "\n",
    "def run_subject(subject_runs):\n",
    "    subject, runs = subject_runs\n",
    "    try:\n",
    "        print('Processing the data for subject: %s' % subject)\n",
    "        os.makedirs(os.path.join(output_folder, 'runLevel', subject), exist_ok=True)\n",
    "        for run in runs:\n",
    "            design_matrix, sample_mask = get_design_matrix(task, subject, run)\n",
    "            fitrunmodel(task, subject, run)\n",
    "        os.makedirs(os.path.join(output_folder, 'subjectLevel', subject), exist_ok=True)\n",
    "        create_sublevelContrasts(subject, runs, task, contrasts_list_sub, template)\n",
    "        with open(os.path.join(output_folder, 'Subjects_Completed_{}_{}.txt'.format(task, template)), \"a\") as f:\n",
    "            f.write(\"{}\\n\".format(subject))\n",
    "    except Exception as error:\n",
    "        print('Subject: %s could not be completed due to the exception %s' % (subject, error))\n",
    "\n",
    "# Example usage of the context manager and multiprocessing\n",
    "with log_redirect():\n",
    "    with Pool(5) as p:  # Using 5 processes for example\n",
    "        p.map(run_subject, list(subjects_to_run.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74a7e3f-b365-423d-82f9-ef95da7d19b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the contrasts for all subjects on a glass brain just to visualize pattern \n",
    "from nilearn import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "for contrast_id in contrasts_list_sub: \n",
    "    subjects_to_plot = sorted(list(set(final_subject_list).intersection(set(map(os.path.basename, glob.glob(os.path.join(output_folder, 'subjectLevel', 'sub-*')))))))\n",
    "    fig, axes = plt.subplots(nrows= math.ceil(len(subjects_to_plot)/5), ncols=5 , squeeze = False)\n",
    "    for i, sub in enumerate(subjects_to_plot):\n",
    "        if contrast_id in contrasts_list:\n",
    "            zmap_path = os.path.join(output_folder, 'subjectLevel', sub, \"{}_task-{}_space-{}_contrast-{}_stat-z_statmap.nii.gz\".format(sub, task,space, contrast_id.lower() ))\n",
    "        else:\n",
    "            zmap_path = os.path.join(output_folder, 'subjectLevel', sub, \"{}_task-{}_space-{}_run-all_contrast-{}_stat-z_statmap.nii.gz\".format(sub, task, space, contrast_id.lower()))\n",
    "            \n",
    "        try:\n",
    "            zmap_img = nilearn.image.load_img(zmap_path)\n",
    "        except ValueError:\n",
    "            zmap_path = os.path.join(output_folder, 'subjectLevel', sub, \"{}_task-{}_space-{}_contrast-{}_stat-effect_statmap.nii.gz\".format(sub, task,  space, contrast_id.lower()))\n",
    "            zmap_img = nilearn.image.load_img(zmap_path)\n",
    "        finally:\n",
    "            plotting.plot_glass_brain(\n",
    "                zmap_img,\n",
    "                colorbar=False,\n",
    "                threshold=3.0,\n",
    "                title = sub[-3:],\n",
    "                axes=axes[i//5,i% 5],\n",
    "                plot_abs=False,\n",
    "                display_mode='z',\n",
    "            )\n",
    "\n",
    "    fig.suptitle('Subjects(z_map) Contrast: {}'.format(contrast_id))\n",
    "    fig.set_size_inches(20, 15)\n",
    "    [fig.delaxes(ax) for ax in axes.flatten() if not ax.has_data()]\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c51fbf-e84b-404b-b4e5-8a2e972898ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
